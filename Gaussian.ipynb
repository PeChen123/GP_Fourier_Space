{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.optimize import minimize\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.linalg import circulant, block_diag\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I generated the joint Gaussian data by using BCCB (block circulant with circulant blocks) covariance matrix as known covariance and mean (mu_k = a + b*k). It allows for easier analysis after applying the FFT to the data due to the specific structure of the data and its covariance.  \n",
    "\n",
    "This idea from this paper: : Jonathan R. Stroud, Michael L. Stein & Shaun Lysen (2017) Bayesian and\n",
    "Maximum Likelihood Estimation for Gaussian Processes on an Incomplete Lattice, Journal of\n",
    "Computational and Graphical Statistics, 26:1, 108-120, DOI: 10.1080/10618600.2016.1152970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation\n",
    "n = 500\n",
    "a_true = 10\n",
    "b_true = 6\n",
    "k = np.linspace(0, n-1, n)\n",
    "mean_true = a_true + b_true * k\n",
    "rng = default_rng(12345)\n",
    "variance = 1.0 \n",
    "\n",
    "# Create block circulant covariance matrix\n",
    "block_size = 2  # For 2x2 circulant blocks\n",
    "if n % block_size != 0:\n",
    "    raise ValueError(\"n must be divisible by block_size\")\n",
    "num_blocks = n // block_size\n",
    "base_block = circulant([variance, -variance])  # Create a 2x2 circulant block\n",
    "blocks = [base_block for _ in range(num_blocks)]\n",
    "block_toeplitz = block_diag(*blocks)\n",
    "\n",
    "# Make the covariance matrix positive definite\n",
    "eigenvalues = np.linalg.eigvals(block_toeplitz)\n",
    "max_eigenvalue = np.max(np.abs(eigenvalues))\n",
    "cov = block_toeplitz + (max_eigenvalue * 1.1) * np.eye(n) \n",
    "y = rng.multivariate_normal(mean_true, cov, size=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1: Given $y_1,y_2,\\ldots,y_N$ are joint Gaussian with mean $\\mathbb{E}[y_k] = \\mu_k$ and the variance is known $\\Sigma$. if $y_k = a + b*k$, how to infer $a$ and $b$\n",
    "\n",
    "In this problem, if we want to infer the parameters, we can consider Maximum Likelihood Estimation which can effectively maximize the probability of a given data set. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, Let $\\theta = [a,b]$. the mean is $\\mu_k = a + b*k$ and $\\Sigma$ is known. \n",
    "\n",
    "I can choose the negetive log-likelihood $-\\ln(L(\\theta|y))  = -\\frac{N}{2}\\ln(2\\pi) + \\frac{1}{2}\\ln|\\Sigma| + \\frac{1}{2} (y - \\mu(\\theta))^T \\Sigma^{-1} (y - \\mu(\\theta))$ from the following reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(theta):\n",
    "    a, b = theta\n",
    "    mu = a + b*k\n",
    "    diff = y - mu\n",
    "    return -n/2*np.log(2*np.pi) + 0.5*np.log(np.linalg.det(cov)) + 0.5*diff.T @ np.linalg.inv(cov) @ diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated a and b: [9.72247909 6.00093156]\n"
     ]
    }
   ],
   "source": [
    "# Initial guess for a and b\n",
    "theta0 = [0, 0]\n",
    "\n",
    "# Optimize\n",
    "res = minimize(neg_log_likelihood, theta0)\n",
    "print(\"Estimated a and b:\", res.x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can see the estimated a and b are almost same as the true a and b that we set. Also, we can get more accurate result by incresing the data size.\n",
    "\n",
    "Reference: https://www.hashpi.com/maximum-likelihood-estimation-and-loss-function-design"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2: Given the Fourier transform of $y_1,y_2,\\ldots,y_N$ are $z_1,z_2,\\ldots,z_N$ , how to infer $a$ and $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT of the data \n",
    "y_fft = fft(y,axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach: we can just use the Inverse Fast Fourier Transfrom for the data set. We can see that results are same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood_complex(theta):\n",
    "    a, b = theta\n",
    "    mu = a + b * k\n",
    "    diff = ifft(y_fft).real - mu  \n",
    "    return -n/2*np.log(2*np.pi) + 0.5*np.log(np.linalg.det(cov)) + 0.5*np.dot(diff.T, np.linalg.solve(cov, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated a and b from FFT data: [9.72247943 6.00093155]\n"
     ]
    }
   ],
   "source": [
    "# Initial guess for a and b\n",
    "theta0 = [0, 0]\n",
    "\n",
    "# Optimize\n",
    "res = minimize(neg_log_likelihood_complex, theta0)\n",
    "print(\"Estimated a and b from FFT data:\", res.x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, We did not access anything from the FFT data. I will explore other approch below trying to firgue out a method in FFT data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach\n",
    "\n",
    "I applied the EM algorithm for analysis the FFT of the given data. Since the goal is to find the parameters $\\theta = [a,b]$ that maximize the expected log-likelihood. This is done iteratively using two steps:\n",
    "\n",
    "E-step: Compute the expected log-likelihood, given the current parameter estimate.\n",
    "$Q(θ|θ^t) = E[log p(Z, Y|θ) | Y, θ^t]$\n",
    "\n",
    "M-step: Update the parameter estimate by maximizing the expected log-likelihood.\n",
    "$θ^t = argmax_{θ} Q(θ|θ^t)$\n",
    "\n",
    "In the code, I turned a maximization problem into a minimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/02lhd2x95j5cdgjwf20qlnc40000gn/T/ipykernel_72366/2884421372.py:15: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  Z_MC = np.array([y_fft + fft(rng.multivariate_normal(np.zeros(n), fft_C.real, size=None)) for _ in range(num)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated a and b from FFT data: [9.7148829  6.00093721]\n"
     ]
    }
   ],
   "source": [
    "# Perform FFT on data and covariance\n",
    "fft_C = fft(cov)\n",
    "fft_C_diag = np.diag(fft_C)\n",
    "\n",
    "# Define log-likelihood function for Monte Carlo EM\n",
    "def log_likelihood_MC(theta, Z):\n",
    "    a, b = theta\n",
    "    mu = a + b * k\n",
    "    mu_fft = fft(mu)\n",
    "    diff_fft = Z - mu_fft\n",
    "    return -0.5 * np.mean(np.abs(diff_fft)**2 / np.abs(fft_C_diag)) - 0.5 * np.sum(np.log(np.abs(fft_C_diag)))\n",
    "\n",
    "# E-step:generating Monte Carlo samples from the FFT-transformed data\n",
    "num = 500\n",
    "Z_MC = np.array([y_fft + fft(rng.multivariate_normal(np.zeros(n), fft_C.real, size=None)) for _ in range(num)])\n",
    "\n",
    "# Initial guess for a and b\n",
    "theta0 = [0, 0]\n",
    "\n",
    "# Optimize (M-step)\n",
    "res = minimize(lambda theta: -log_likelihood_MC(theta, Z_MC), theta0)\n",
    "\n",
    "print(\"Estimated a and b from FFT data:\", res.x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this method, I obtained the a and b are same as previous. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
